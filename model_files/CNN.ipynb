{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cd39b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226955 files belonging to 214 classes.\n",
      "Using 204260 files for training.\n"
     ]
    }
   ],
   "source": [
    "# Obtaining Training Dataset from Local Directory\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Aug_Dataset\"\n",
    "    , labels = 'inferred'\n",
    "    , label_mode = 'int'\n",
    "    , image_size=(100, 140)\n",
    "    , color_mode = 'grayscale'\n",
    "    , shuffle = True\n",
    "    , seed = 101\n",
    "    , validation_split = 0.1\n",
    "    , subset = \"training\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f065467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226955 files belonging to 214 classes.\n",
      "Using 22695 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Obtaining Validation Dataset from Local Directory\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Aug_Dataset\"\n",
    "    , labels = 'inferred'\n",
    "    , label_mode = 'int'\n",
    "    , image_size=(100, 140)\n",
    "    , color_mode = 'grayscale'\n",
    "    , shuffle = True\n",
    "    , seed = 101\n",
    "    , validation_split = 0.1\n",
    "    , subset = \"validation\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5d5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de76ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 96, 136, 32)       832       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 96, 136, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 27, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 23, 64)        51264     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 15, 23, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 214)               27606     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 214)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,134\n",
      "Trainable params: 178,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Dropout, Flatten\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), input_shape = (100,140,1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(214))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c46283",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6384/6384 [==============================] - 666s 104ms/step - loss: 3.9239 - accuracy: 0.1577 - val_loss: 1.7133 - val_accuracy: 0.5191\n",
      "Epoch 2/200\n",
      "6384/6384 [==============================] - 575s 90ms/step - loss: 1.6414 - accuracy: 0.5356 - val_loss: 0.9798 - val_accuracy: 0.7044\n",
      "Epoch 3/200\n",
      "6384/6384 [==============================] - 599s 94ms/step - loss: 1.3193 - accuracy: 0.6146 - val_loss: 0.8934 - val_accuracy: 0.7306\n",
      "Epoch 4/200\n",
      "6384/6384 [==============================] - 594s 93ms/step - loss: 1.1983 - accuracy: 0.6465 - val_loss: 0.7649 - val_accuracy: 0.7584\n",
      "Epoch 5/200\n",
      "6384/6384 [==============================] - 553s 87ms/step - loss: 1.1174 - accuracy: 0.6685 - val_loss: 0.6851 - val_accuracy: 0.7822\n",
      "Epoch 6/200\n",
      "6384/6384 [==============================] - 541s 85ms/step - loss: 1.0725 - accuracy: 0.6827 - val_loss: 0.6609 - val_accuracy: 0.7937\n",
      "Epoch 7/200\n",
      "6384/6384 [==============================] - 537s 84ms/step - loss: 1.0585 - accuracy: 0.6883 - val_loss: 0.8696 - val_accuracy: 0.7326\n",
      "Epoch 8/200\n",
      "6384/6384 [==============================] - 534s 84ms/step - loss: 1.0064 - accuracy: 0.6994 - val_loss: 0.6438 - val_accuracy: 0.7993\n",
      "Epoch 9/200\n",
      "6384/6384 [==============================] - 535s 84ms/step - loss: 1.0124 - accuracy: 0.6989 - val_loss: 0.6296 - val_accuracy: 0.8010\n",
      "Epoch 10/200\n",
      "6384/6384 [==============================] - 532s 83ms/step - loss: 0.9787 - accuracy: 0.7082 - val_loss: 0.5895 - val_accuracy: 0.8142\n",
      "Epoch 11/200\n",
      "6384/6384 [==============================] - 530s 83ms/step - loss: 0.8310 - accuracy: 0.7471 - val_loss: 0.6034 - val_accuracy: 0.8095\n",
      "Epoch 12/200\n",
      "6384/6384 [==============================] - 527s 83ms/step - loss: 0.7648 - accuracy: 0.7658 - val_loss: 0.5338 - val_accuracy: 0.8322\n",
      "Epoch 13/200\n",
      "6384/6384 [==============================] - 528s 83ms/step - loss: 0.7205 - accuracy: 0.7792 - val_loss: 0.4789 - val_accuracy: 0.8437\n",
      "Epoch 14/200\n",
      "6384/6384 [==============================] - 527s 83ms/step - loss: 0.7308 - accuracy: 0.7773 - val_loss: 0.5026 - val_accuracy: 0.8398\n",
      "Epoch 15/200\n",
      "6384/6384 [==============================] - 528s 83ms/step - loss: 0.6939 - accuracy: 0.7876 - val_loss: 0.4726 - val_accuracy: 0.8515\n",
      "Epoch 16/200\n",
      "6384/6384 [==============================] - 528s 83ms/step - loss: 0.6702 - accuracy: 0.7948 - val_loss: 0.4650 - val_accuracy: 0.8523\n",
      "Epoch 17/200\n",
      "6384/6384 [==============================] - 532s 83ms/step - loss: 0.6667 - accuracy: 0.7980 - val_loss: 0.4544 - val_accuracy: 0.8572\n",
      "Epoch 18/200\n",
      "6384/6384 [==============================] - 543s 85ms/step - loss: 0.6567 - accuracy: 0.8011 - val_loss: 0.4956 - val_accuracy: 0.8418\n",
      "Epoch 19/200\n",
      "6384/6384 [==============================] - 532s 83ms/step - loss: 0.6505 - accuracy: 0.8028 - val_loss: 0.4277 - val_accuracy: 0.8631\n",
      "Epoch 20/200\n",
      "6384/6384 [==============================] - 530s 83ms/step - loss: 0.6720 - accuracy: 0.7963 - val_loss: 0.4625 - val_accuracy: 0.8548\n",
      "Epoch 21/200\n",
      "6384/6384 [==============================] - 530s 83ms/step - loss: 0.6630 - accuracy: 0.8000 - val_loss: 0.4530 - val_accuracy: 0.8573\n",
      "Epoch 22/200\n",
      "6384/6384 [==============================] - 540s 85ms/step - loss: 0.6385 - accuracy: 0.8077 - val_loss: 0.5032 - val_accuracy: 0.8412\n",
      "Epoch 23/200\n",
      "6383/6384 [============================>.] - ETA: 0s - loss: 0.6425 - accuracy: 0.8064Restoring model weights from the end of the best epoch: 19.\n",
      "6384/6384 [==============================] - 532s 83ms/step - loss: 0.6425 - accuracy: 0.8064 - val_loss: 0.4872 - val_accuracy: 0.8489\n",
      "Epoch 23: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad68eac280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs = 200, batch_size = 32, verbose = 1, validation_data = val_data, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e098685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 96, 136, 32)       832       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 96, 136, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 19, 27, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 15, 23, 64)        51264     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 15, 23, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 4, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               98432     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 214)               27606     \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 214)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,134\n",
      "Trainable params: 178,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dense, Dropout, Flatten\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (5, 5), input_shape = (100,140,1)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "model2.add(Conv2D(64, (5, 5)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(5,5)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten()) \n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation(\"relu\"))\n",
    "\n",
    "model2.add(Dense(214))\n",
    "model2.add(Activation(\"softmax\"))\n",
    "\n",
    "model2.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b66e4457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6384/6384 [==============================] - 632s 99ms/step - loss: 4.3743 - accuracy: 0.0990 - val_loss: 2.3406 - val_accuracy: 0.3936\n",
      "Epoch 2/200\n",
      "6384/6384 [==============================] - 629s 99ms/step - loss: 2.1195 - accuracy: 0.4368 - val_loss: 1.3615 - val_accuracy: 0.6085\n",
      "Epoch 3/200\n",
      "6384/6384 [==============================] - 642s 101ms/step - loss: 1.5589 - accuracy: 0.5634 - val_loss: 0.9368 - val_accuracy: 0.7172\n",
      "Epoch 4/200\n",
      "6384/6384 [==============================] - 663s 104ms/step - loss: 1.3964 - accuracy: 0.6021 - val_loss: 0.9851 - val_accuracy: 0.7093\n",
      "Epoch 5/200\n",
      "6384/6384 [==============================] - 588s 92ms/step - loss: 1.3138 - accuracy: 0.6216 - val_loss: 1.0270 - val_accuracy: 0.6887\n",
      "Epoch 6/200\n",
      "6384/6384 [==============================] - 618s 97ms/step - loss: 1.2658 - accuracy: 0.6356 - val_loss: 2.6341 - val_accuracy: 0.4560\n",
      "Epoch 7/200\n",
      "6384/6384 [==============================] - 614s 96ms/step - loss: 1.2299 - accuracy: 0.6448 - val_loss: 0.8636 - val_accuracy: 0.7310\n",
      "Epoch 8/200\n",
      "6384/6384 [==============================] - 554s 87ms/step - loss: 1.1984 - accuracy: 0.6526 - val_loss: 0.7621 - val_accuracy: 0.7651\n",
      "Epoch 9/200\n",
      "6384/6384 [==============================] - 539s 84ms/step - loss: 1.1752 - accuracy: 0.6601 - val_loss: 0.9437 - val_accuracy: 0.7084\n",
      "Epoch 10/200\n",
      "6384/6384 [==============================] - 543s 85ms/step - loss: 1.1477 - accuracy: 0.6666 - val_loss: 0.8060 - val_accuracy: 0.7557\n",
      "Epoch 11/200\n",
      "6384/6384 [==============================] - 552s 86ms/step - loss: 1.1728 - accuracy: 0.6642 - val_loss: 0.7953 - val_accuracy: 0.7567\n",
      "Epoch 12/200\n",
      "6384/6384 [==============================] - 545s 85ms/step - loss: 1.1027 - accuracy: 0.6767 - val_loss: 0.7172 - val_accuracy: 0.7779\n",
      "Epoch 13/200\n",
      "6384/6384 [==============================] - 547s 86ms/step - loss: 1.0915 - accuracy: 0.6815 - val_loss: 0.6537 - val_accuracy: 0.7948\n",
      "Epoch 14/200\n",
      "6384/6384 [==============================] - 549s 86ms/step - loss: 1.0888 - accuracy: 0.6838 - val_loss: 0.7089 - val_accuracy: 0.7759\n",
      "Epoch 15/200\n",
      "6384/6384 [==============================] - 549s 86ms/step - loss: 2.2009 - accuracy: 0.5023 - val_loss: 4.6961 - val_accuracy: 0.0326\n",
      "Epoch 16/200\n",
      "6384/6384 [==============================] - 559s 88ms/step - loss: 3.4989 - accuracy: 0.2439 - val_loss: 0.7947 - val_accuracy: 0.7562\n",
      "Epoch 17/200\n",
      "6383/6384 [============================>.] - ETA: 0s - loss: 1.2921 - accuracy: 0.6466Restoring model weights from the end of the best epoch: 13.\n",
      "6384/6384 [==============================] - 554s 87ms/step - loss: 1.2921 - accuracy: 0.6466 - val_loss: 0.7095 - val_accuracy: 0.7810\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad00039c60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model2.fit(train_data, epochs = 200, batch_size = 32, verbose = 1, validation_data = val_data, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88daca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_path = \"samples/aug_0_209.png\"\n",
    "\n",
    "def prepare(file):\n",
    "#     IMG_SIZE = 50\n",
    "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "#     new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return img_array.reshape(-1, 100, 140, 1)\n",
    "\n",
    "img = prepare(img_path)\n",
    "pred = model2.predict([img])\n",
    "\n",
    "pred = list(pred[0])\n",
    "char_type = class_names[pred.index(max(pred))]\n",
    "print(char_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc03530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_val_loss_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
